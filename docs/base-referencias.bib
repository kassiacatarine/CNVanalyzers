% This file was created with JabRef 2.10b2.
% Encoding: UTF-8

@article{Chong2015,
abstract = {Discovering the genetic basis of a Mendelian phenotype establishes a causal link between genotype and phenotype, making possible carrier and population screening and direct diagnosis. Such discoveries also contribute to our knowledge of gene function, gene regulation, development, and biological mechanisms that can be used for developing new therapeutics. As of February 2015, 2,937 genes underlying 4,163 Mendelian phenotypes have been discovered, but the genes underlying ∼50{\%} (i.e., 3,152) of all known Mendelian phenotypes are still unknown, and many more Mendelian conditions have yet to be recognized. This is a formidable gap in biomedical knowledge. Accordingly, in December 2011, the NIH established the Centers for Mendelian Genomics (CMGs) to provide the collaborative framework and infrastructure necessary for undertaking large-scale whole-exome sequencing and discovery of the genetic variants responsible for Mendelian phenotypes. In partnership with 529 investigators from 261 institutions in 36 countries, the CMGs assessed 18,863 samples from 8,838 families representing 579 known and 470 novel Mendelian phenotypes as of January 2015. This collaborative effort has identified 956 genes, including 375 not previously associated with human health, that underlie a Mendelian phenotype. These results provide insight into study design and analytical strategies, identify novel mechanisms of disease, and reveal the extensive clinical variability of Mendelian phenotypes. Discovering the gene underlying every Mendelian phenotype will require tackling challenges such as worldwide ascertainment and phenotypic characterization of families affected by Mendelian conditions, improvement in sequencing and analytical techniques, and pervasive sharing of phenotypic and genomic data among researchers, clinicians, and families.},
author = {Chong, Jessica X. and Buckingham, Kati J. and Jhangiani, Shalini N. and Boehm, Corinne and Sobreira, Nara and Smith, Joshua D. and Harrell, Tanya M. and McMillin, Margaret J. and Wiszniewski, Wojciech and Gambin, Tomasz and {Coban Akdemir}, Zeynep H. and Doheny, Kimberly and Scott, Alan F. and Avramopoulos, Dimitri and Chakravarti, Aravinda and Hoover-Fong, Julie and Mathews, Debra and Witmer, P. Dane and Ling, Hua and Hetrick, Kurt and Watkins, Lee and Patterson, Karynne E. and Reinier, Frederic and Blue, Elizabeth and Muzny, Donna and Kircher, Martin and Bilguvar, Kaya and L{\'{o}}pez-Gir{\'{a}}ldez, Francesc and Sutton, V. Reid and Tabor, Holly K. and Leal, Suzanne M. and Gunel, Murat and Mane, Shrikant and Gibbs, Richard A. and Boerwinkle, Eric and Hamosh, Ada and Shendure, Jay and Lupski, James R. and Lifton, Richard P. and Valle, David and Nickerson, Deborah A. and Bamshad, Michael J.},
doi = {10.1016/j.ajhg.2015.06.009},
file = {:C$\backslash$:/Users/K{\'{a}}ssia/Downloads/The Genetic Basis of Mendelian Phenotypes.pdf:pdf},
issn = {15376605},
journal = {American Journal of Human Genetics},
number = {2},
pages = {199--215},
title = {{The Genetic Basis of Mendelian Phenotypes: Discoveries, Challenges, and Opportunities}},
volume = {97},
year = {2015}
}
@article{Correa2008,
abstract = {Este artigo apresenta um panorama das implica{\c{c}}{\~{o}}es sociais, {\'{e}}ticas e legais do Projeto Genoma Humano. Os benef{\'{i}}cios desse megaprojeto, traduzidos em promessas de uma revolu{\c{c}}{\~{a}}o terap{\^{e}}utica na medicina, n{\~{a}}o se realizar{\~{a}}o sem conflitos. O processo de inova{\c{c}}{\~{a}}o tecnol{\'{o}}gica na gen{\'{e}}tica traz problemas de ordens diversas: por um lado, pesquisas em cons{\'{o}}rcio, patenteamento de genes e produtos da gen{\^{o}}mica apontam interesses comerciais e dificuldades de gerenciamento dos resultados dessas pesquisas. Esses problemas colocam desafios em termos de uma poss{\'{i}}vel desigualdade no acesso aos benef{\'{i}}cios das pesquisas. Por outro lado, temos a quest{\~{a}}o da informa{\c{c}}{\~{a}}o gen{\'{e}}tica e da prote{\c{c}}{\~{a}}o de dados individuais sobre riscos e suscetibilidades a doen{\c{c}}as e atributos humanos. O problema da defini{\c{c}}{\~{a}}o de homens e mulheres em fun{\c{c}}{\~{a}}o de tra{\c{c}}os gen{\'{e}}ticos traz uma amea{\c{c}}a discriminat{\'{o}}ria clara, e se torna agudo em fun{\c{c}}{\~{a}}o do reducionismo gen{\'{e}}tico que a m{\'{i}}dia ajuda a propagar. As respostas a esses problemas n{\~{a}}o podem ser esperadas apenas da bio{\'{e}}tica. A abordagem bio{\'{e}}tica deve poder combinar-se a an{\'{a}}lises pol{\'{i}}ticas da reprodu{\c{c}}{\~{a}}o, da sexualidade, da sa{\'{u}}de e da medicina. Um vast{\'{i}}ssimo espectro de problemas como estes n{\~{a}}o pode ser discutido em profundidade em um artigo. Optou-se por mape{\'{a}}-los no sentido de enfatizar em que medida, na reflex{\~{a}}o sobre o projeto genoma, a gen{\^{o}}mica e a p{\'{o}}s-gen{\^{o}}mica, enfrenta-se o desafio de articular aspectos t{\~{a}}o diferenciados.This article presents an overview of the social, ethical, and legal implications of the Human Genome Project. The benefits of this mega-project, expressed as promises of a therapeutic revolution in medicine, will not be achieved without conflict. The process of technological innovation in genetics poses problems of various orders: on the one hand, consortium-based research, gene patenting, and genomic products tend to feature commercial interests and management of the results of such research. These problems raise challenges in terms of possible inequality in access to the benefits of research. On the other hand, we have the issue of genetic information and safeguarding individual data concerning the risks and susceptibilities to human diseases and characteristics. Defining men and women as a function of genetic traits poses a clear discriminatory threat and becomes even more acute as a function of the genetic reductionism propagated by the mass media. Answers to these problems cannot be expected only from bioethics. The bioethical approach should be combined with political analyses concerning reproduction, sexuality, health, and medicine. Such a vast range of problems cannot be discussed in depth in a single article. The choice was thus made to map them in the sense of emphasizing to what extent, in reflecting on the Genome Project, genomics, and post-genomics, the challenge is met to link such diverse aspects.},
author = {Corr{\^{e}}a, Marilena V.},
doi = {10.1590/s0103-73312002000200006},
file = {:C$\backslash$:/Users/K{\'{a}}ssia/Downloads/O Admir{\'{a}}vel Projeto Genoma Humano - Marilena V. Corr{\^{e}}a.pdf:pdf},
journal = {Physis: Revista de Sa{\'{u}}de Coletiva},
number = {2},
pages = {277--299},
title = {{O admir{\'{a}}vel Projeto Genoma Humano}},
volume = {12},
year = {2008}
}
@article{Robinson2011,
abstract = {In whole-exome sequencing (WES), target capture methods are used to enrich the sequences of the coding regions of genes from fragmented total genomic DNA, followed by massively parallel, 'next-generation' sequencing of the captured fragments. Since its introduction in 2009, WES has been successfully used in several disease-gene discovery projects, but the analysis of whole-exome sequence data can be challenging. In this overview, we present a summary of the main computational strategies that have been applied to identify novel disease genes in whole-exome data, including intersect filters, the search for de novo mutations, and the application of linkage mapping or inference of identity-by-descent (IBD) in family studies.},
author = {Robinson, Pn and Krawitz, P. and Mundlos, S.},
doi = {10.1111/j.1399-0004.2011.01713.x},
file = {:home/akira/Downloads/Robinson{\_}et{\_}al-2011-Clinical{\_}Genetics.pdf:pdf},
issn = {00099163},
journal = {Clinical Genetics},
keywords = {Bioinformatics,Disease gene,Exome,Genome,Next-generation sequencing},
number = {2},
pages = {127--132},
title = {{Strategies for exome and genome sequence data analysis in disease-gene discovery projects}},
volume = {80},
year = {2011}
}

@article{Metzker2010,
abstract = {Demand has never been greater for revolutionary technologies that deliver fast, inexpensive and accurate genome information. This challenge has catalysed the development of next-generation sequencing (NGS) technologies. The inexpensive production of large volumes of sequence data is the primary advantage over conventional methods. Here, I present a technical review of template preparation, sequencing and imaging, genome alignment and assembly approaches, and recent advances in current and near-term commercially available NGS instruments. I also outline the broad range of applications for NGS technologies, in addition to providing guidelines for platform selection to address biological questions of interest.},
author = {Metzker, Michael L},
doi = {10.1038/nrg2626},
file = {:home/akira/Downloads/Sequencing technologies - the next generation.pdf:pdf},
issn = {1471-0064},
journal = {Nature reviews. Genetics},
number = {1},
pages = {31--46},
pmid = {19997069},
publisher = {Nature Publishing Group},
title = {{Sequencing technologies - the next generation.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19997069},
volume = {11},
year = {2010}
}

@article{Xi2011,
abstract = {DNA copy number variations (CNVs) play an important role in the pathogenesis and progression of cancer and confer susceptibility to a variety of human disorders. Array comparative genomic hybridization has been used widely to identify CNVs genome wide, but the next-generation sequencing technology provides an opportunity to characterize CNVs genome wide with unprecedented resolution. In this study, we developed an algorithm to detect CNVs from whole-genome sequencing data and applied it to a newly sequenced glioblastoma genome with a matched control. This read-depth algorithm, called BIC-seq, can accurately and efficiently identify CNVs via minimizing the Bayesian information criterion. Using BIC-seq, we identified hundreds of CNVs as small as 40 bp in the cancer genome sequenced at 10× coverage, whereas we could only detect large CNVs ({\textgreater} 15 kb) in the array comparative genomic hybridization profiles for the same genome. Eighty percent (14/16) of the small variants tested (110 bp to 14 kb) were experimentally validated by quantitative PCR, demonstrating high sensitivity and true positive rate of the algorithm. We also extended the algorithm to detect recurrent CNVs in multiple samples as well as deriving error bars for breakpoints using a Gibbs sampling approach. We propose this statistical approach as a principled yet practical and efficient method to estimate CNVs in whole-genome sequencing data.},
author = {Xi, R. and Hadjipanayis, A. G. and Luquette, L. J. and Kim, T.-M. and Lee, E. and Zhang, J. and Johnson, M. D. and Muzny, D. M. and Wheeler, D. A. and Gibbs, R. A. and Kucherlapati, R. and Park, P. J.},
doi = {10.1073/pnas.1110574108},
file = {:home/akira/Downloads/Copy number variation detection.pdf:pdf},
issn = {0027-8424},
journal = {Proceedings of the National Academy of Sciences},
number = {46},
pages = {E1128--E1136},
title = {{Copy number variation detection in whole-genome sequencing data using the Bayesian information criterion}},
volume = {108},
year = {2011}
}

@article{Mills2011,
abstract = {Genomic structural variants (SVs) are abundant in humans, differing from other forms of variation in extent, origin and functional impact. Despite progress in SV characterization, the nucleotide resolution architecture of most SVs remains unknown. We constructed a map of unbalanced SVs (that is, copy number variants) based on whole genome DNA sequencing data from 185 human genomes, integrating evidence from complementary SV discovery approaches with extensive experimental validations. Our map encompassed 22,025 deletions and 6,000 additional SVs, including insertions and tandem duplications. Most SVs (53{\%}) were mapped to nucleotide resolution, which facilitated analysing their origin and functional impact. We examined numerous whole and partial gene deletions with a genotyping approach and observed a depletion of gene disruptions amongst high frequency deletions. Furthermore, we observed differences in the size spectra of SVs originating from distinct formation mechanisms, and constructed a map of SV hotspots formed by common mechanisms. Our analytical framework and SV map serves as a resource for sequencing-based association studies.},
author = {Mills, Ryan E. and Walter, Klaudia and Stewart, Chip and Handsaker, Robert E. and Chen, Ken and Alkan, Can and Abyzov, Alexej and Yoon, Seungtai Chris and Ye, Kai and Cheetham, R. Keira and Chinwalla, Asif and Conrad, Donald F. and Fu, Yutao and Grubert, Fabian and Hajirasouliha, Iman and Hormozdiari, Fereydoun and Iakoucheva, Lilia M. and Iqbal, Zamin and Kang, Shuli and Kidd, Jeffrey M. and Konkel, Miriam K. and Korn, Joshua and Khurana, Ekta and Kural, Deniz and Lam, Hugo Y.K. and Leng, Jing and Li, Ruiqiang and Li, Yingrui and Lin, Chang Yun and Luo, Ruibang and Mu, Xinmeng Jasmine and Nemesh, James and Peckham, Heather E. and Rausch, Tobias and Scally, Aylwyn and Shi, Xinghua and Stromberg, Michael P. and S{\"{u}}tz, Adrian M. and Urban, Alexander Eckehart and Walker, Jerilyn A. and Wu, Jiantao and Zhang, Yujun and Zhang, Zhengdong D. and Batzer, Mark A. and Ding, Li and Marth, Gabor T. and McVean, Gil and Sebat, Jonathan and Snyder, Michael and Wang, Jun and Ye, Kenny and Eichler, Evan E. and Gerstein, Mark B. and Hurles, Matthew E. and Lee, Charles and McCarroll, Steven A. and Korbel, Jan O. and Collins, Francis S.},
doi = {10.1038/nature09708},
file = {:home/akira/Downloads/Mapping copy number variation by population-scale genome sequencing.pdf:pdf},
issn = {14764687},
journal = {Nature},
number = {7332},
pages = {59--65},
title = {{Mapping copy number variation by population-scale genome sequencing}},
volume = {470},
year = {2011}
}

@article{Aminikhanghahi2017,
abstract = {Change points are abrupt variations in time series data. Such abrupt changes may represent transitions that occur between states. Detection of change points is useful in modelling and prediction of time series and is found in application areas such as medical condition monitoring, climate change detection, speech and image analysis, and human activity analysis. This survey article enumerates, categorizes, and compares many of the methods that have been proposed to detect change points in time series. The methods examined include both supervised and unsupervised algorithms that have been introduced and evaluated. We introduce several criteria to compare the algorithms. Finally, we present some grand challenges for the community to consider.},
author = {Aminikhanghahi, Samaneh and Cook, Diane J.},
doi = {10.1007/s10115-016-0987-z},
file = {:home/akira/Downloads/Aminikhanghahi-Cook2017{\_}Article{\_}ASurveyOfMethodsForTimeSeriesC.pdf:pdf},
issn = {02193116},
journal = {Knowledge and Information Systems},
keywords = {Change point detection,Data mining,Machine learning,Segmentation,Time series data},
number = {2},
pages = {339--367},
publisher = {Springer London},
title = {{A survey of methods for time series change point detection}},
volume = {51},
year = {2017}
}


@article{Marian2011,
abstract = {To discuss implications of information garnered through whole-genome and exome sequencing in the practice of cardiovascular medicine.},
author = {Marian, Ali J.},
doi = {10.1097/HCO.0b013e3283459857},
file = {:home/akira/Downloads/Medical DNA sequencing.pdf:pdf},
issn = {02684705},
journal = {Current Opinion in Cardiology},
keywords = {genetic testing,genetics,next-generation sequencing,polymorphism},
number = {3},
pages = {175--180},
title = {{Medical DNA sequencing}},
volume = {26},
year = {2011}
}

@article{Lander2001,
author = {Lander, Eric S.; Linton and Birren, Lauren M.; and Nusbaum, Bruce; and Zody, Chad; and Baldwin, Michael C.; and Devon, Jennifer; and Dewar, Keri; and Doyle, Ken; and FitzHugh, Michael; and Funke, William; and Gage, Roel; and Harris, Diane; and Heaford, Katrina; and Howland, Andrew; and Kann, John; and Lehoczky, Lisa; and LeVine, Jessica; and McEwan, Rosie; and McKernanKevin., Paul;},
file = {:home/akira/Downloads/Initial sequencing and analysis of the.pdf:pdf},
journal = {Nature},
number = {6822},
title = {{Initial sequencing and analysis of the human genome}},
volume = {409},
year = {2001}
}

@book{Rye2017,
author = {Rye, Connie},
file = {:home/akira/Downloads/biology-10.4.pdf:pdf},
isbn = {9781938168093},
pages = {1480},
title = {{Biology}},
year = {2017}
}

@article{Sharma2016,
abstract = {Trend analysis and change point detection in a time series are frequent analysis tools. Change point detec- tion is the identification of abrupt variation in the process behavior due to distributional or structural changes, whereas trend can be defined as estimation of gradual departure from past norms. We examine four different change point detec- tion methods which, by virtue of current literature, appear to be the most widely used and the newest algorithms. They are Wild Binary Segmentation, E-Agglomerative algorithm for change point, Iterative Robust Detection method and Baye- sian Analysis of Change Points. We measure the power and accuracy of these current methods using simulated data. We draw comparisons on the functionality and usefulness of each method. We also analyze the data in the presence of trend, using Mann–Kendall and Cox–Stuart methods toge- ther with the change point algorithms, in order to evaluate whether presence of trend affects change point or vice versa.},
author = {Sharma, Shilpy and Swayne, David A. and Obimbo, Charlie},
doi = {10.1007/s40974-016-0011-1},
file = {:home/akira/Downloads/Sharma2016{\_}Article{\_}TrendAnalysisAndChangePointTec.pdf:pdf},
issn = {2363-7692},
journal = {Energy, Ecology and Environment},
keywords = {Change point analysis,LO(W)ESS,Trend analysis,change point analysis {\'{a}},trend analysis {\'{a}}},
number = {3},
pages = {123--130},
publisher = {Joint Center on Global Change and Earth System Science of the University of Maryland and Beijing Normal University},
title = {{Trend analysis and change point techniques: a survey}},
volume = {1},
year = {2016}
}

@article{Dierssen2009,
abstract = {Quantitative differences in gene expression emerge as a significant source of variation in natural populations, representing an important substrate for evolution and accounting for a considerable fraction of phenotypic diversity. However, perturbation of gene expression is also the main factor in determining the molecular pathogenesis of numerous aneuploid disorders. In this review, we focus on Down syndrome (DS) as the prototype of "genomic disorder" induced by copy number change. The understanding of the pathogenicity of the extra genomic material in trisomy 21 has accelerated in the last years due to the recent advances in genome sequencing, comparative genome analysis, functional genome exploration, and the use of model organisms. We present recent data on the role of genome-altering processes in the generation of diversity in DS neural phenotypes focusing on the impact of trisomy on brain structure and mental retardation and on biological pathways and cell types in target brain regions (including prefrontal cortex, hippocampus, cerebellum, and basal ganglia). We also review the potential that genetically engineered mouse models of DS bring into the understanding of the molecular biology of human learning disorders.},
author = {Dierssen, Mara and Herault, Yann and Estivill, Xavier},
doi = {10.1152/physrev.00032.2007},
file = {:home/akira/Downloads/Aneuploidy{\_} From a Physiological Mechanism of Variance to Down Syndrome.pdf:pdf},
issn = {0031-9333},
journal = {Physiological Reviews},
number = {3},
pages = {887--920},
title = {{Aneuploidy: From a Physiological Mechanism of Variance to Down Syndrome}},
volume = {89},
year = {2009}
}

@article{Edwards2011,
abstract = {DNA sequencing allows the decoding of the genetic code, facilitating the discovery of the molecular genetic basis of biological systems. Knowledge of the sequence of genes in cereals provides a key to understanding many of their nutritional and functional properties. For many years DNA sequencing technology advanced slowly with incremental advances in the di-deoxy or Sanger method. New technologies are now greatly increasing the power of DNA sequencing. Second (next) generation sequencing has dramatically reduced the cost of DNA sequencing and increased the amount of data that can be collected. Further advances exploiting third generation sequencing promise to accelerate these developments. The DNA sequences of cereal species, genotypes or even individual seeds can now be obtained delivering a new level of capability in cereal science. {\textcopyright} 2011 Elsevier Ltd.},
author = {Edwards, M. A. and Henry, R. J.},
doi = {10.1016/j.jcs.2011.07.006},
file = {:home/akira/Downloads/DNA sequencing methods contributing to new directions in cereal research.pdf:pdf},
issn = {07335210},
journal = {Journal of Cereal Science},
keywords = {DNA sequencing},
number = {3},
pages = {395--400},
publisher = {Elsevier Ltd},
title = {{DNA sequencing methods contributing to new directions in cereal research}},
url = {http://dx.doi.org/10.1016/j.jcs.2011.07.006},
volume = {54},
year = {2011}
}

@Manual{Core2019,
  title        = {R: A Language and Environment for Statistical
                  Computing},
  author       = {{R Core Team}},
  organization = {R Foundation for Statistical Computing},
  address      = {Vienna, Austria},
  year         = 2019,
  url          = {https://www.R-project.org},
  note = {Acesso em: 26 de Abril de 2019}
}

@misc{website:Hornik2018,
      author = "Kurt Hornik",
      title = "R FAQ",
      year = "2018",
      note = "Acesso em: 26 de Abril de 2019",
      url = "https://CRAN.R-project.org/doc/FAQ/R-FAQ.html"
}

@Manual{Seshan2018,
    title = {DNAcopy: DNA copy number data analysis},
    author = {Venkatraman E. Seshan and Adam Olshen},
    year = {2018},
    note = {R package version 1.56.0},
}

@article{Polunchenko2012,
author = { Aleksey S.   Polunchenko  and  Alexander G.   Tartakovsky  and  Nitis   Mukhopadhyay },
title = {Nearly Optimal Change-Point Detection with an Application to Cybersecurity},
journal = {Sequential Analysis},
volume = {31},
number = {3},
pages = {409-435},
year  = {2012},
publisher = {Taylor & Francis},
doi = {10.1080/07474946.2012.694351},

URL = { 
        https://www.tandfonline.com/doi/abs/10.1080/07474946.2012.694351
    
},
eprint = { 
        https://www.tandfonline.com/doi/pdf/10.1080/07474946.2012.694351
    
}
,
    abstract = { Abstract We address the sequential change-point detection problem for the Gaussian model where baseline distribution is Gaussian with variance σ2 and mean μ such that σ2 = aμ, where a > 0 is a known constant; the change is in μ from one known value to another. First, we carry out a comparative performance analysis of four detection procedures: the Cumulative Sum (CUSUM) procedure, the Shiryaev–Roberts (SR) procedure, and two its modifications—the Shiryaev–Roberts–Pollak and Shiryaev–Roberts–r procedures. The performance is benchmarked via Pollak's maximal average delay to detection and Shiryaev's stationary average delay to detection, each subject to a fixed average run length to false alarm. The analysis shows that in practically interesting cases the accuracy of asymptotic approximations is “reasonable” to “excellent”. We also consider an application of change-point detection to cybersecurity for rapid anomaly detection in computer networks. Using real network data we show that statistically traffic's intensity can be well described by the proposed Gaussian model with σ2 = aμ instead of the traditional Poisson model, which requires σ2 = μ. By successively devising the SR and CUSUM procedures to “catch” a low-contrast network anomaly (caused by an Internet Control Message Protocol reflector attack), we then show that the SR rule is quicker. We conclude that the SR procedure is a better cyber “watch dog” than the popular CUSUM procedure. }
}

@article{Bates2012,
abstract = {Over recent years, considerable attention has been given to the problem of detecting trends and change points (discontinuities) in climatic series. This has led to the use of a plethora of detection techniques, ranging from the very simple (e.g., linear regression and t-tests) to the relatively complex (e.g., Markov chain Monte Carlo methods). However, many of these techniques are quite restricted in their range of application and care is needed to avoid misinterpretation of their results. In this paper we highlight the availability of modern regression methods that allow for both smooth trends and abrupt changes, and a discontinuity test that enables discrimination between the two. Our framework can accommodate constant mean levels, linear or smooth trends, and can test for genuine change points in an objective and data-driven way. We demonstrate its capabilities using the winter (December–March) North Atlantic Oscillation, an annual mean relative humidity series and a seasonal (June to October) typhoon count series as case studies. We show that the framework is less restrictive than many alternatives in allowing the data to speak for themselves and can give different and more credible results from those of conventional methods. The research findings from such analyses can be used to appropriately inform the design of subsequent studies of temporal changes in underlying physical mechanisms, and the development of policy responses that are appropriate for smoothly varying rather than abrupt climate change (and vice versa).},
author = {Bates, Bryson C. and Chandler, Richard E. and Bowman, Adrian W.},
doi = {10.1029/2011JD017077},
file = {:home/akira/Downloads/Bates{\_}et{\_}al-2012-Journal{\_}of{\_}Geophysical{\_}Research{\_}{\_}Atmospheres{\_}(1984-2012).pdf:pdf},
issn = {01480227},
journal = {Journal of Geophysical Research Atmospheres},
keywords = {North Atlantic Oscillation,change points,time series,trend estimation,typhoons},
number = {16},
pages = {1--9},
title = {{Trend estimation and change point detection in individual climatic series using flexible regression methods}},
volume = {117},
year = {2012}
}

@article{Fan2015,
abstract = {Research on change-point detection, the classical problem of detecting abrupt changes in sequential data, has focused predominantly on datasets with a single observable. A growing number of time series datasets, however, involve many observables, often with the property that a given change typically affects only a few of the observables. We introduce a general statistical method that, given many noisy observables, detects points in time at which various subsets of the observables exhibit simultaneous changes in data distribution and explicitly identifies those subsets. Our work is motivated by the problem of identifying the nature and timing of biologically interesting conformational changes that occur during atomic-level simulations of biomolecules such as proteins. This problem has proved challenging both because each such conformational change might involve only a small region of the molecule and because these changes are often subtle relative to the ever-present background of faster structural fluctuations. We show that our method is effective in detecting biologically interesting conformational changes in molecular dynamics simulations of both folded and unfolded proteins, even in cases where these changes are difficult to detect using alternative techniques. This method may also facilitate the detection of change points in other types of sequential data involving large numbers of observables--a problem likely to become increasingly important as such data continue to proliferate in a variety of application domains.},
author = {Fan, Zhou and Dror, Ron O. and Mildorf, Thomas J. and Piana, Stefano and Shaw, David E.},
doi = {10.1073/pnas.1415846112},
file = {:home/akira/Downloads/Identifying localized changes in large systems.pdf:pdf},
issn = {0027-8424},
journal = {Proceedings of the National Academy of Sciences},
number = {24},
pages = {7454--7459},
title = {{Identifying localized changes in large systems: Change-point detection for biomolecular simulations}},
volume = {112},
year = {2015}
}

@article{Ruuska2018,
abstract = {The aim of the present study was to evaluate empirically confusion matrices in device validation. We compared the confusion matrix method to linear regression and error indices in the validation of a device measuring feeding behaviour of dairy cattle. In addition, we studied how to extract additional information on classification errors with confusion probabilities. The data consisted of 12 h behaviour measurements from five dairy cows; feeding and other behaviour were detected simultaneously with a device and from video recordings. The resulting 216 000 pairs of classifications were used to construct confusion matrices and calculate performance measures. In addition, hourly durations of each behaviour were calculated and the accuracy of measurements was evaluated with linear regression and error indices. All three validation methods agreed when the behaviour was detected very accurately or inaccurately. Otherwise, in the intermediate cases, the confusion matrix method and error indices produced relatively concordant results, but the linear regression method often disagreed with them. Our study supports the use of confusion matrix analysis in validation since it is robust to any data distribution and type of relationship, it makes a stringent evaluation of validity, and it offers extra information on the type and sources of errors.},
author = {Ruuska, Salla and H{\"{a}}m{\"{a}}l{\"{a}}inen, Wilhelmiina and Kajava, Sari and Mughal, Mikaela and Matilainen, Pekka and Mononen, Jaakko},
doi = {10.1016/j.beproc.2018.01.004},
file = {:home/akira/Downloads/Evaluation of the confusion matrix method in the validation of an automated.pdf:pdf},
issn = {18728308},
journal = {Behavioural Processes},
keywords = {Confusion matrix,Confusion probabilities,Error indices,Feeding behaviour,Linear regression,Validation},
number = {March 2017},
pages = {56--62},
publisher = {Elsevier},
title = {{Evaluation of the confusion matrix method in the validation of an automated system for measuring feeding behaviour of cattle}},
url = {https://doi.org/10.1016/j.beproc.2018.01.004},
volume = {148},
year = {2018}
}

@article{Killick2012,
abstract = {We consider the problem of detecting multiple changepoints in large data sets. Our focus is on applications where the number of changepoints will increase as we collect more data: for example in genetics as we analyse larger regions of the genome, or in finance as we observe time-series over longer periods. We consider the common approach of detecting changepoints through minimising a cost function over possible numbers and locations of changepoints. This includes several established procedures for detecting changing points, such as penalised likelihood and minimum description length. We introduce a new method for finding the minimum of such cost functions and hence the optimal number and location of changepoints that has a computational cost which, under mild conditions, is linear in the number of observations. This compares favourably with existing methods for the same problem whose computational cost can be quadratic or even cubic. In simulation studies we show that our new method can be orders of magnitude faster than these alternative exact methods. We also compare with the Binary Segmentation algorithm for identifying changepoints, showing that the exactness of our approach can lead to substantial improvements in the accuracy of the inferred segmentation of the data.},
author = {Killick, R. and Fearnhead, P. and Eckley, I. A.},
doi = {10.1080/01621459.2012.737745},
file = {:home/akira/Downloads/Optimal Detection of Changepoints With a Linear Computational Cost.pdf:pdf},
issn = {01621459},
journal = {Journal of the American Statistical Association},
keywords = {Dynamic programming,PELT,Segmentation,Structural change},
number = {500},
pages = {1590--1598},
title = {{Optimal detection of changepoints with a linear computational cost}},
volume = {107},
year = {2012}
}

@article{Gioumousis2005,
author = {Gioumousis, P. and {Tun Tao Tsai} and Scargle, J.D. and Arabhi, S. and Gwin, E. and Alt, A. and Tan, L. and Jackson, B. and San, P. and Barnes, D.},
doi = {10.1109/lsp.2001.838216},
file = {:home/akira/Downloads/An Algorithm for Optimal Partitioning.pdf:pdf},
issn = {1070-9908},
journal = {IEEE Signal Processing Letters},
number = {2},
pages = {105--108},
title = {{An algorithm for optimal partitioning of data on an interval}},
volume = {12},
year = {2005}
}

@article{BenedicteBakka2018,
author = {{Benedicte Bakka}, Kristin},
file = {:home/akira/Downloads/Changepoint model selection in Gaussian data by maximization of approximate Bayes Factors.pdf:pdf},
number = {June},
title = {{Changepoint model selection in Gaussian data by maximization of approximate Bayes Factors with the Pruned Exact Linear Time algorithm}},
url = {https://brage.bibsys.no/xmlui/bitstream/handle/11250/2558597/19876{\_}FULLTEXT.pdf?sequence=1{\&}isAllowed=y},
year = {2018}
}

@article{Uzai2019,
abstract = {Time series are sequence of values distributed over time. Analyzing time series is important in many areas including medical, financial, aerospace, commercial and entertainment. Change Point Detection is the problem of identifying changes in meaning or distribution of data in a time series. This article presents Spec, a new algorithm that uses the graph spectrum to detect change points. The Spec was evaluated using the UCR Archive which is a large da- tabase of different time series. Spec performance was compared to the PELT, ECP, EDM, and gSeg algorithms. The results showed that Spec achieved a better accuracy compared to the state of the art in some specific scenarios and as efficient as in most cases evaluated.},
author = {Uzai, Luis Gustavo C. and Kashiwabara, Andr{\'{e}} Y.},
doi = {10.5753/eniac.2018.4461},
file = {:home/akira/Downloads/4461-949-4419-1-10-20181130.pdf:pdf},
pages = {716--727},
title = {{Using Graph Spectral to solve Change Point Detection Problems}},
year = {2019}
}

@Inbook{Chen1-2000,
author="Chen, Jie
and Gupta, A. K.",
title="Preliminaries",
bookTitle="Parametric Statistical Change Point Analysis",
year="2000",
publisher="Birkh{\"a}user Boston",
address="Boston, MA",
pages="1--4",
abstract="The world is filled with changes. An awareness of these changes can help people to avoid unnecessary losses and to harness beneficial transitions. In many practical situations a statistician is faced with the problem of detecting the number of change points or jumps and their locations. This is known as the change point problem, and its impact may be seen in a large number of practical problems from many disciplines.",
isbn="978-1-4757-3131-6",
doi="10.1007/978-1-4757-3131-6_1",
url="https://doi.org/10.1007/978-1-4757-3131-6_1"
}

@Inbook{Chen2-2000,
author="Chen, Jie
and Gupta, A. K.",
title="Univariate Normal Model",
bookTitle="Parametric Statistical Change Point Analysis",
year="2000",
publisher="Birkh{\"a}user Boston",
address="Boston, MA",
pages="5--63",
abstract="Let x1, x2, ..., xnbe a sequence of independent normal random variables with parameters {\%} MathType!MTEF!2!1!+-{\%} feaaguart1ev2aaatCvAUfeBSjuyZL2yd9gzLbvyNv2CaerbuLwBLn{\%} hiov2DGi1BTfMBaeXatLxBI9gBaerbd9wDYLwzYbItLDharqqtubsr{\%} 4rNCHbGeaGqiVu0Je9sqqrpepC0xbbL8F4rqqrFfpeea0xe9Lq-Jc9{\%} vqaqpepm0xbba9pwe9Q8fs0-yqaqpepae9pg0FirpepeKkFr0xfr-x{\%} fr-xb9adbaqaaeGaciGaaiaabeqaamaabaabaaGcbaGaaiikaiabeY{\%} 7aTnaaBaaaleaacaaIXaaabeaakiaacYcacqaHdpWCdaqhaaWcbaGa{\%} aGymaaqaaiaaikdaaaGccaGGPaGaaiilaiaaygW7caaMe8Uaaiikai{\%} abeY7aTnaaBaaaleaacaaIYaaabeaakiaacYcacqaHdpWCdaqhaaWc{\%} baGaaGOmaaqaaiaaikdaaaGccaGGPaGaaiilaiaaysW7caGGUaGaai{\%} Olaiaac6cacaGGSaGaaGjbVlaacIcacqaH8oqBdaWgaaWcbaGaamOB{\%} aaqabaGccaGGSaGaeq4Wdm3aa0baaSqaaiaad6gaaeaacaaIYaaaaO{\%} Gaaiykaaaa!591E!{\$}{\$} ({\{}{\backslash}mu {\_}1{\}},{\backslash}sigma {\_}1^2),{\backslash};({\{}{\backslash}mu {\_}2{\}},{\backslash}sigma {\_}2^2),{\backslash};...,{\backslash};({\{}{\backslash}mu {\_}n{\}},{\backslash}sigma {\_}n^2) {\$}{\$}, respectively. In this chapter, different types of change point problems with regard to the mean, variance, and mean and variance will be discussed in the upcoming sections.",
isbn="978-1-4757-3131-6",
doi="10.1007/978-1-4757-3131-6_2",
url="https://doi.org/10.1007/978-1-4757-3131-6_2"
}

@article{Cheon2010,
abstract = {Bayesian multiple change-point models are proposed for multivariate means. The models require that the data be from a multivariate normal distribution with a truncated Poisson prior for the number of change-points and conjugate priors for the distributional parameters. We apply the stochastic approximation Monte Carlo (SAMC) algorithm to the multiple change-point detection problems. Numerical results show that SAMC makes a significant improvement over RJMCMC for complex Bayesian model selection problems in change-point estimation. {\textcopyright} 2009 Elsevier B.V. All rights reserved.},
author = {Cheon, Sooyoung and Kim, Jaehee},
doi = {10.1016/j.csda.2009.09.003},
file = {:home/akira/Downloads/Multiple change-point detection of multivariate mean vectors with the.pdf:pdf},
issn = {01679473},
journal = {Computational Statistics and Data Analysis},
number = {2},
pages = {406--415},
publisher = {Elsevier B.V.},
title = {{Multiple change-point detection of multivariate mean vectors with the Bayesian approach}},
url = {http://dx.doi.org/10.1016/j.csda.2009.09.003},
volume = {54},
year = {2010}
}

@article{Shi2017,
abstract = {{\textcopyright} 2017, National Academy of Sciences. All rights reserved. A change-point detection is proposed by using a Bayesian-type statistic based on the shortest Hamiltonian path, and the change-point is estimated by using ratio cut. A permutation procedure is applied to approximate the significance of Bayesian-type statistics. The change-point test is proven to be consistent, and an error probability in change-point estimation is provided. The test is very powerful against alternatives with a shift in variance and is accurate in change-point estimation, as shown in simulation studies. Its applicability in tracking cell division is illustrated.},
author = {Shi, Xiaoping and Wu, Yuehua and Rao, Calyampudi Radhakrishna},
doi = {10.1073/pnas.1702654114},
file = {:home/akira/Downloads/Consistent and powerful graph-based change-point.pdf:pdf},
issn = {0027-8424},
journal = {Proceedings of the National Academy of Sciences},
number = {15},
pages = {3873--3878},
title = {{Consistent and powerful graph-based change-point test for high-dimensional data}},
volume = {114},
year = {2017}
}

@article{Feuk2006,
abstract = {There is growing appreciation that the human genome contains significant numbers of structural rearrangements, such as insertions, deletions, inversions, and large tandem repeats. Recent studies have defined approximately 5{\%} of the human genome as structurally variant in the normal population, involving more than 800 independent genes. We present a detailed review of the various structural rearrangements identified to date in humans, with particular reference to their influence on human phenotypic variation. Our current knowledge of the extent of human structural variation shows that the human genome is a highly dynamic structure that shows significant large-scale variation from the currently published genome reference sequence.},
author = {Feuk, Lars and Carson, Andrew R. and Scherer, Stephen W.},
doi = {10.1038/nrg1767},
file = {:home/akira/Downloads/Structural variation in the human genome.pdf:pdf},
issn = {14710056},
journal = {Nature Reviews Genetics},
number = {2},
pages = {85--97},
title = {{Structural variation in the human genome}},
volume = {7},
year = {2006}
}

@article{Deng2016,
abstract = {The determination of basic probability assignment (BPA) is a crucial issue in the application of Dempster-Shafer evidence theory. Classification is a process of determining the class label that a sample belongs to. In classification problem, the construction of BPA based on the confusion matrix has been studied. However, the existing methods do not make full use of the available information provided by the confusion matrix. In this paper, an improved method to construct the BPA is proposed based on the confusion matrix. The proposed method takes into account both the precision rate and the recall rate of each class. An illustrative case regarding the prediction of transmembrane protein topology is given to demonstrate the effectiveness of the proposed method.},
author = {Deng, Xinyang and Liu, Qi and Deng, Yong and Mahadevan, Sankaran},
doi = {10.1016/j.ins.2016.01.033},
file = {:home/akira/Downloads/An improved method to construct basic probability.pdf:pdf},
issn = {00200255},
journal = {Information Sciences},
keywords = {Basic probability assignment,Belief function,Classification,Confusion matrix,Dempster-Shafer evidence theory,Transmembrane proteins},
pages = {250--261},
publisher = {Elsevier Inc.},
title = {{An improved method to construct basic probability assignment based on the confusion matrix for classification problem}},
url = {http://dx.doi.org/10.1016/j.ins.2016.01.033},
volume = {340-341},
year = {2016}
}

@article{Bamshad2011,
author = {Bamshad, Michael J and Ng, Sarah B and Bigham, Abigail W and Tabor, Holly K and Emond, Mary J and Nickerson, Deborah A and Shendure, Jay},
file = {:home/akira/Downloads/nrg3031.pdf:pdf},
journal = {Nature Reviews Genetics},
month = {sep},
pages = {745},
publisher = {Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
title = {{Exome sequencing as a tool for Mendelian disease gene discovery}},
url = {https://doi.org/10.1038/nrg3031 http://10.0.4.14/nrg3031 https://www.nature.com/articles/nrg3031{\#}supplementary-information},
volume = {12},
year = {2011}
}

@article{Ng2009,
abstract = {Genome-wide association studies suggest that common genetic variants explain only a modest fraction of heritable risk for common diseases, raising the question of whether rare variants account for a significant fraction of unexplained heritability. Although DNA sequencing costs have fallen markedly, they remain far from what is necessary for rare and novel variants to be routinely identified at a genome-wide scale in large cohorts. We have therefore sought to develop second-generation methods for targeted sequencing of all protein-coding regions ('exomes'), to reduce costs while enriching for discovery of highly penetrant variants. Here we report on the targeted capture and massively parallel sequencing of the exomes of 12 humans. These include eight HapMap individuals representing three populations, and four unrelated individuals with a rare dominantly inherited disorder, Freeman-Sheldon syndrome (FSS). We demonstrate the sensitive and specific identification of rare and common variants in over 300 megabases of coding sequence. Using FSS as a proof-of-concept, we show that candidate genes for Mendelian disorders can be identified by exome sequencing of a small number of unrelated, affected individuals. This strategy may be extendable to diseases with more complex genetics through larger sample sizes and appropriate weighting of non-synonymous variants by predicted functional impact.},
author = {Ng, Sarah B and Turner, Emily H and Robertson, Peggy D and Flygare, Steven D and Bigham, Abigail W and Lee, Choli and Shaffer, Tristan and Wong, Michelle and Bhattacharjee, Arindam and Eichler, Evan E and Bamshad, Michael and Nickerson, Deborah A and Shendure, Jay},
doi = {10.1038/nature08250},
edition = {2009/08/16},
file = {:home/akira/Downloads/nihms-128791.pdf:pdf},
issn = {1476-4687},
journal = {Nature},
language = {eng},
month = {sep},
number = {7261},
pages = {272--276},
title = {{Targeted capture and massively parallel sequencing of 12 human exomes}},
url = {https://www.ncbi.nlm.nih.gov/pubmed/19684571 https://www.ncbi.nlm.nih.gov/pmc/PMC2844771/},
volume = {461},
year = {2009}
}

@article{Lee2014,
abstract = {Clinical exome sequencing (CES) is rapidly becoming a common molecular diagnostic test for individuals with rare genetic disorders.To report on initial clinical indications for CES referrals and molecular diagnostic rates for different indications and for different test types.Clinical exome sequencing was performed on 814 consecutive patients with undiagnosed, suspected genetic conditions at the University of California, Los Angeles, Clinical Genomics Center between January 2012 and August 2014. Clinical exome sequencing was conducted as trio-CES (both parents and their affected child sequenced simultaneously) to effectively detect de novo and compound heterozygous variants or as proband-CES (only the affected individual sequenced) when parental samples were not available.Clinical indications for CES requests, molecular diagnostic rates of CES overall and for phenotypic subgroups, and differences in molecular diagnostic rates between trio-CES and proband-CES.Of the 814 cases, the overall molecular diagnosis rate was 26{\%} (213 of 814; 95{\%} CI, 23{\%}-29{\%}). The molecular diagnosis rate for trio-CES was 31{\%} (127 of 410 cases; 95{\%} CI, 27{\%}-36{\%}) and 22{\%} (74 of 338 cases; 95{\%} CI, 18{\%}-27{\%}) for proband-CES. In cases of developmental delay in children ({\textless}5 years, n = 138), the molecular diagnosis rate was 41{\%} (45 of 109; 95{\%} CI, 32{\%}-51{\%}) for trio-CES cases and 9{\%} (2 of 23, 95{\%} CI, 1{\%}-28{\%}) for proband-CES cases. The significantly higher diagnostic yield (P value = .002; odds ratio, 7.4 [95{\%} CI, 1.6-33.1]) of trio-CES was due to the identification of de novo and compound heterozygous variants.In this sample of patients with undiagnosed, suspected genetic conditions, trio-CES was associated with higher molecular diagnostic yield than proband-CES or traditional molecular diagnostic methods. Additional studies designed to validate these findings and to explore the effect of this approach on clinical and economic outcomes are warranted.},
author = {Lee, Hane and Deignan, Joshua L and Dorrani, Naghmeh and Strom, Samuel P and Kantarci, Sibel and Quintero-Rivera, Fabiola and Das, Kingshuk and Toy, Traci and Harry, Bret and Yourshaw, Michael and Fox, Michelle and Fogel, Brent L and Martinez-Agosto, Julian A and Wong, Derek A and Chang, Vivian Y and Shieh, Perry B and Palmer, Christina G S and Dipple, Katrina M and Grody, Wayne W and Vilain, Eric and Nelson, Stanley F},
doi = {10.1001/jama.2014.14604},
issn = {0098-7484},
journal = {JAMA},
month = {nov},
number = {18},
pages = {1880--1887},
title = {{Clinical Exome Sequencing for Genetic Identification of Rare Mendelian DisordersClinical Exome Sequencing for Genetic Identification of Rare Mendelian DisordersClinical Exome Sequencing for Genetic Identification of Rare Mendelian Disorders}},
url = {https://doi.org/10.1001/jama.2014.14604},
volume = {312},
year = {2014}
}

@article{Antonarakis2006,
abstract = {Multifactorial disorders have grabbed the limelight in recent years, at the expense of research on monogenic traits. This shift in emphasis might not be fully justified, given the insight that seemingly 'simple' disorders can bring to genome function and complex disease aetiology.},
author = {Antonarakis, Stylianos E and Beckmann, Jacques S},
doi = {10.1038/nrg1826},
file = {:home/akira/Downloads/nrg1826.pdf:pdf},
issn = {1471-0064},
journal = {Nature Reviews Genetics},
mendeley-groups = {TCC},
number = {4},
pages = {277--282},
title = {{Mendelian disorders deserve more attention}},
url = {https://doi.org/10.1038/nrg1826},
volume = {7},
year = {2006}
}

@article{Likar2018,
abstract = {Hereditary hearing loss (HL) is a common sensory disorder, with an incidence of 1–2 per 1000 newborns, and has a genetic etiology in over 50{\%} of cases. It occurs either as part of a syndrome or in isolation and is genetically very heterogeneous which poses a challenge for clinical and molecular diagnosis. We used exome sequencing to seek a genetic cause in a group of 56 subjects (49 probands) with HL: 32 with non-syndromic non-GJB2 HL and 17 with syndromic HL. Following clinical examination and clinical exome sequencing, an etiological diagnosis was established in 15 probands (15/49; 30{\%}); eight (8/17;47{\%}) from the syndromic group and seven (7/32; 21{\%}) from the non-syndromic non-GJB2 subgroup. Fourteen different (half of them novel) non-GJB2 variants causing HL were found in 10 genes (CHD7, HDAC8, MITF, NEFL, OTOF, SF3B4, SLC26A4, TECTA, TMPRSS3, USH2A) among 13 probands, confirming the genetic heterogeneity of hereditary HL. Different genetic causes for HL were found in a single family while three probands with apparent syndromic HL were found to have HL as a separate clinical feature, distinct from the complex phenotype. Clinical exome sequencing proved to be an effective tool used to comprehensively address the genetic heterogeneity of HL, to detect clinically unrecognized HL syndromes, and to decipher complex phenotypes in which HL is a separate feature and not part of a syndrome. [ABSTRACT FROM AUTHOR]},
annote = {Accession Number: 127062059; Likar, Tina 1 Hasanhod{\v{z}}i{\'{c}}, Mensuda 2 Teran, Nata{\v{s}}a 1 Maver, Ale{\v{s}} 1 Peterlin, Borut 1 Writzl, Karin 1; Email Address: karinwritzl@gmail.com; Affiliation: 1: Clinical Institute of Medical Genetics, University Medical Centre Ljubljana, Ljubljana, Slovenia 2: Policlinic of Medical Genetics with Genetic Counseling for Out-Patient Care, Department of Paediatrics, University Clinical Centre Tuzla, Tuzla, Bosnia and Herzegovina; Source Info: 1/2/2018, Vol. 13 Issue 1, p1; Subject Term: DIAGNOSIS of deafness; Subject Term: DNA sequencing; Subject Term: PHENOTYPES; Subject Term: OTOLOGY; Subject Term: HEALTH outcome assessment; Author-Supplied Keyword: Biology and life sciences; Author-Supplied Keyword: Clinical genetics; Author-Supplied Keyword: Deafness; Author-Supplied Keyword: Diagnostic medicine; Author-Supplied Keyword: Gene sequencing; Author-Supplied Keyword: Genetic testing; Author-Supplied Keyword: Genetics; Author-Supplied Keyword: Genomic medicine; Author-Supplied Keyword: Genomics; Author-Supplied Keyword: Hearing disorders; Author-Supplied Keyword: Human genetics; Author-Supplied Keyword: Medicine and health sciences; Author-Supplied Keyword: Molecular biology; Author-Supplied Keyword: Molecular biology techniques; Author-Supplied Keyword: Otology; Author-Supplied Keyword: Otorhinolaryngology; Author-Supplied Keyword: Pathogens; Author-Supplied Keyword: Pathology and laboratory medicine; Author-Supplied Keyword: Phenotypes; Author-Supplied Keyword: Research and analysis methods; Author-Supplied Keyword: Research Article; Author-Supplied Keyword: Sequencing techniques; Number of Pages: 14p; Document Type: Article; Full Text Word Count: 7061},
author = {Likar, Tina and Hasanhod{\v{z}}i{\'{c}}, Mensuda and Teran, Nata{\v{s}}a and Maver, Ale{\v{s}} and Peterlin, Borut and Writzl, Karin},
file = {:home/akira/Downloads/ContentServer.pdf:pdf},
issn = {19326203},
journal = {PLoS ONE},
keywords = {Biology and life sciences,Clinical genetics,DIAGNOSIS of deafness,DNA sequencing,Deafness,Diagnostic medicine,Gene sequencing,Genetic testing,Genetics,Genomic medicine,Genomics,HEALTH outcome assessment,Hearing disorders,Human genetics,Medicine and health sciences,Molecular biology,Molecular biology techniques,OTOLOGY,Otology,Otorhinolaryngology,PHENOTYPES,Pathogens,Pathology and laboratory medicine,Phenotypes,Research Article,Research and analysis methods,Sequencing techniques},
mendeley-groups = {TCC},
month = {jan},
number = {1},
pages = {1--14},
publisher = {Public Library of Science},
title = {{Diagnostic outcomes of exome sequencing in patients with syndromic or non-syndromic hearing loss.}},
url = {http://10.0.5.91/journal.pone.0188578 http://search.ebscohost.com/login.aspx?direct=true{\&}db=aph{\&}AN=127062059{\&}lang=pt-br{\&}site=ehost-live},
volume = {13},
year = {2018}
}

@article{Allen2016,
abstract = {Summary Early onset epileptic encephalopathies (EOEEs) represent a significant diagnostic challenge. Newer genomic approaches have begun to elucidate an increasing number of responsible single genes as well as emerging diagnostic strategies. In this single-center study, we aimed to investigate a cohort of children with unexplained EOEE. We performed whole-exome sequencing (WES), targeting a list of 137 epilepsy-associated genes on 50 children with unexplained EOEE. We characterized all phenotypes in detail and classified children according to known electroclinical syndromes where possible. Infants with previous genetic diagnoses, causative brain malformations, or inborn errors of metabolism were excluded. We identified disease-causing variants in 11 children (22{\%}) in the following genes: STXBP1 (n = 3), KCNB1 (n = 2), KCNT1, SCN1A, SCN2A, GRIN2A, DNM1, and KCNA2. We also identified two further variants (in GRIA3 and CPA6) in two children requiring further investigation. Eleven variants were de novo, and in one paternal testing was not possible. Phenotypes were broadened for some variants identified. This study demonstrates that WES is a clinically useful screening tool for previously investigated unexplained EOEE and allows for reanalysis of data as new genes are being discovered. Detailed phenotyping allows for expansion of specific gene disorders leading to epileptic encephalopathy and emerging sub-phenotypes.},
annote = {doi: 10.1111/epi.13250},
author = {Allen, Nicholas M and Conroy, Judith and Shahwan, Amre and Lynch, Bryan and Correa, Raony G and Pena, Sergio D J and McCreary, Dara and Magalh{\~{a}}es, Tiago R and Ennis, Sean and Lynch, Sally A and King, Mary D},
doi = {10.1111/epi.13250},
file = {:home/akira/Downloads/Allen{\_}et{\_}al-2016-Epilepsia.pdf:pdf},
issn = {0013-9580},
journal = {Epilepsia},
keywords = {encephalopathy,epilepsy,infantile spasms},
mendeley-groups = {TCC},
month = {jan},
number = {1},
pages = {e12--e17},
publisher = {John Wiley {\&} Sons, Ltd (10.1111)},
title = {{Unexplained early onset epileptic encephalopathy: Exome screening and phenotype expansion}},
url = {https://doi.org/10.1111/epi.13250},
volume = {57},
year = {2016}
}

@article{Lin2019,
abstract = {Monogenic diabetes is caused by mutations that reduce $\beta$-cell function. While Sanger sequencing is the standard method used to detect mutated genes. Next-generation sequencing techniques, such as whole exome sequencing (WES), can be used to find multiple gene mutations in one assay. We used WES to detect genetic mutations in both permanent neonatal (PND) and type 1B diabetes (T1BD). A total of five PND and nine T1BD patients were enrolled in this study. WES variants were assessed using VarioWatch, excluding those identified previously. Sanger sequencing was used to confirm the mutations, and their pathogenicity was established via the literature or bioinformatic/functional analysis. The PND and T1BD patients were diagnosed at 0.1–0.5 and 0.8–2.7 years of age, respectively. Diabetic ketoacidosis was present at diagnosis in 60{\%} of PND patients and 44.4{\%} of T1BD patients. We found five novel mutations in five different genes. Notably, patient 602 had a novel homozygous missense mutation c.1295C {\textgreater} A (T432 K) in the glucokinase (GCK) gene. Compared to the wild-type recombinant protein, the mutant protein had significantly lower enzymatic activity (2.5{\%}, p = 0.0002) and Vmax (1.23 ± 0.019 vs. 0.33 ± 0.016, respectively; p = 0.005). WES is a robust technique that can be used to unravel the etiologies of genetically heterogeneous forms of diabetes. Homozygous inactivating mutations of the GCK gene may have a significant role in PND pathogenesis.},
author = {Lin, Dao-Chen and Huang, Chi-Yu and Ting, Wei-Hsin and Lo, Fu-Sung and Lin, Chiung-Ling and Yang, Horng-Woei and Chang, Tzu-Yang and Lin, Chao-Hsu and Tzeng, Yao-Wei and Yang, Wan-Syuan and Juang, Yue-Li and Lee, Yann-Jinn},
doi = {https://doi.org/10.1016/j.bbadis.2018.11.013},
file = {:home/akira/Downloads/1-s2.0-S0925443918304745-main.pdf:pdf},
issn = {0925-4439},
journal = {Biochimica et Biophysica Acta (BBA) - Molecular Basis of Disease},
keywords = {Glucokinase,Monogenic diabetes,Neonatal diabetes,Whole exome sequencing},
mendeley-groups = {TCC},
number = {2},
pages = {428--433},
title = {{Mutations in glucokinase and other genes detected in neonatal and type 1B diabetes patient using whole exome sequencing may lead to disease-causing changes in protein activity}},
url = {http://www.sciencedirect.com/science/article/pii/S0925443918304745},
volume = {1865},
year = {2019}
}

@article{Fu2019,
abstract = {Background Congenital hypothyroidism (CH) is the most common neonatal endocrine disorder. Although most patients present with isolated CH, some patients present with CH and extra-thyroidal congenital malformations (ECMs), for which less is known about the underlying genetics. The aim of this study was to investigate the genetic mechanisms in patients with CH and ECMs using chromosomal microarray (CMA) and whole exome sequencing (WES). Methods Peripheral venous blood samples were collected from 16 patients with CH and ECMs. Genomic DNA was extracted from peripheral blood leukocytes. CMA and WES were performed to detect copy number and single nucleotide variants. Results CMA identified clinically significant copy number variants in 7 patients consistent with their phenotypes. For 6 of them, the genotype and phenotype suggested a syndromic diagnosis, and the remaining patient carried a pathogenic microdeletion and microduplication including GLIS3. WES analysis identified 9 different variants in 7 additional patients. The variants included 2 known mutations (c.1096C{\textgreater}T (p.Arg366Trp) in KCNQ1 and c.848C{\textgreater}A (p.Pro283Gln) in NKX2-5) and 7 novel variants: one nonsense mutation (c.4330C{\textgreater}T (p.Arg1444*) in ASXL3), one frameshift mutation (c.1253{\_}1259delACTCTGG (p.Asp418fs) in TG), three missense variants (c.1472C{\textgreater}T (p.Thr491Ile) in TG, c.4604A{\textgreater}G (p.Asp1535Gly) in TG, and c.2139G{\textgreater}T (p.Glu713Asp) in DUOX2, and two splice site variants (c.944-1G{\textgreater}C and c.3693 + 1G{\textgreater}T) in DUOX2. Conclusions We report the first genetic study of CH patients with ECMs using CMA and WES. Overall, our detection rate for pathogenic and possibly pathogenic variants was 87.5{\%} (14/16). We report 7 novel variants, expanding the mutational spectrum of TG, DUOX2, and ASXL3.},
author = {Fu, Chunyun and Luo, Shiyu and Zhang, Yue and Fan, Xin and D'Gama, Alissa M and Zhang, Xiaofei and Zheng, Haiyang and Su, Jiasun and Li, Chuan and Luo, Jingsi and Agrawal, Pankaj B and Li, Qifei and Chen, Shaoke},
doi = {https://doi.org/10.1016/j.cca.2018.11.035},
file = {:home/akira/Downloads/1-s2.0-S0009898118306168-main.pdf:pdf},
issn = {0009-8981},
journal = {Clinica Chimica Acta},
keywords = {Chromosomal microarray,Congenital hypothyroidism,Extra-thyroidal congenital malformations,Whole exome sequencing},
mendeley-groups = {TCC},
pages = {103--108},
title = {{Chromosomal microarray and whole exome sequencing identify genetic causes of congenital hypothyroidism with extra-thyroidal congenital malformations}},
url = {http://www.sciencedirect.com/science/article/pii/S0009898118306168},
volume = {489},
year = {2019}
}

@article{Sanger1975,
abstract = {A simple and rapid method for determining nucleotide sequences in single-stranded DNA by primed synthesis with DNA polymerase is described. It depends on the use of Escherichia coli DNA polymerase I and DNA polymerase from bacteriophage T4 under conditions of different limiting nucleoside triphosphates and concurrent fractionation of the products according to size by ionophoresis on acrylamide gels. The method was used to determine two sequences in bacteriophage $\phi$X174 DNA using the synthetic decanucleotide A-G-A-A-A-T-A-A-A-A and a restriction enzyme digestion product as primers.},
author = {Sanger, F and Coulson, A R},
doi = {https://doi.org/10.1016/0022-2836(75)90213-2},
file = {:home/akira/Downloads/1-s2.0-0022283675902132-main.pdf:pdf},
issn = {0022-2836},
journal = {Journal of Molecular Biology},
mendeley-groups = {TCC},
number = {3},
pages = {441--448},
title = {{A rapid method for determining sequences in DNA by primed synthesis with DNA polymerase}},
url = {http://www.sciencedirect.com/science/article/pii/0022283675902132},
volume = {94},
year = {1975}
}

@article{HutchisonIII2007,
abstract = {Fifteen years elapsed between the discovery of the double helix (1953) and the first DNA sequencing (1968). Modern DNA sequencing began in 1977, with development of the chemical method of Maxam and Gilbert and the dideoxy method of Sanger, Nicklen and Coulson, and with the first complete DNA sequence (phage ϕX174), which demonstrated that sequence could give profound insights into genetic organization. Incremental improvements allowed sequencing of molecules {\textgreater}200 kb (human cytomegalovirus) leading to an avalanche of data that demanded computational analysis and spawned the field of bioinformatics. The US Human Genome Project spurred sequencing activity. By 1992 the first ‘sequencing factory' was established, and others soon followed. The first complete cellular genome sequences, from bacteria, appeared in 1995 and other eubacterial, archaebacterial and eukaryotic genomes were soon sequenced. Competition between the public Human Genome Project and Celera Genomics produced working drafts of the human genome sequence, published in 2001, but refinement and analysis of the human genome sequence will continue for the foreseeable future. New ‘massively parallel' sequencing methods are greatly increasing sequencing capacity, but further innovations are needed to achieve the ‘thousand dollar genome' that many feel is prerequisite to personalized genomic medicine. These advances will also allow new approaches to a variety of problems in biology, evolution and the environment.},
author = {{Hutchison III}, Clyde A},
doi = {10.1093/nar/gkm688},
file = {:home/akira/Downloads/gkm688.pdf:pdf},
issn = {0305-1048},
journal = {Nucleic Acids Research},
mendeley-groups = {TCC},
month = {sep},
number = {18},
pages = {6227--6237},
title = {{DNA sequencing: bench to bedside and beyond †}},
url = {https://doi.org/10.1093/nar/gkm688},
volume = {35},
year = {2007}
}

@article{McCallum1977,
author = {McCallum, Duncan and Smith, Michael},
doi = {https://doi.org/10.1016/0022-2836(77)90116-4},
file = {:home/akira/Downloads/1-s2.0-0022283677901164-main.pdf:pdf},
issn = {0022-2836},
journal = {Journal of Molecular Biology},
mendeley-groups = {TCC},
number = {1},
pages = {29--30},
title = {{Computer processing of DNA sequence data}},
url = {http://www.sciencedirect.com/science/article/pii/0022283677901164},
volume = {116},
year = {1977}
}

@article{Bennett2004,
abstract = {Solexa Ltd is developing an integrated system, based on a breakthrough single molecule sequencing technology, to address a US{\$}2 billion market that is expected to grow exponentially alongside and as a consequence of further technological enhancements. The system, software and consumables will initially be sold to research organizations, pharmaceutical companies and diagnostic companies that will sequence large regions of genomic DNA, including whole genomes, at costs several orders of magnitude below current levels. Solexa expects to launch its first product in 2006, and as it continues to make time and cost efficiencies, additional products will be launched into the expanding markets that will have broad applications in basic research through to healthcare management.},
annote = {doi: 10.1517/14622416.5.4.433},
author = {Bennett, Simon},
doi = {10.1517/14622416.5.4.433},
issn = {1462-2416},
journal = {Pharmacogenomics},
mendeley-groups = {TCC},
month = {jun},
number = {4},
pages = {433--438},
publisher = {Future Medicine},
title = {{Solexa Ltd}},
url = {https://doi.org/10.1517/14622416.5.4.433},
volume = {5},
year = {2004}
}

@article{Linnarsson2010,
abstract = {DNA sequencing has revolutionized biomedicine, and progress in the field has been unrelenting since it was invented over 30years ago. The complete DNA sequence of the human genome was obtained as the culmination of a decade of work by a large number of scientists. Less than ten years later, so-called ‘next-generation' instruments now make it possible for a single lab to produce the same amount of data in a week. But while the instruments are increasingly automated, upstream sample processing remains a challenge. Here I review the current state of the art in preparing genomic and RNA samples for high throughput sequencing.},
author = {Linnarsson, Sten},
doi = {https://doi.org/10.1016/j.yexcr.2010.02.036},
file = {:home/akira/Downloads/1-s2.0-S0014482710000984-main.pdf:pdf},
issn = {0014-4827},
journal = {Experimental Cell Research},
keywords = {DNA sequencing,RNA-Seq,Sample preparation},
mendeley-groups = {TCC},
number = {8},
pages = {1339--1343},
title = {{Recent advances in DNA sequencing methods – general principles of sample preparation}},
url = {http://www.sciencedirect.com/science/article/pii/S0014482710000984},
volume = {316},
year = {2010}
}

@article{Zhao2013,
abstract = {Copy number variation (CNV) is a prevalent form of critical genetic variation that leads to an abnormal number of copies of large genomic regions in a cell. Microarray-based comparative genome hybridization (arrayCGH) or genotyping arrays have been standard technologies to detect large regions subject to copy number changes in genomes until most recently high-resolution sequence data can be analyzed by next-generation sequencing (NGS). During the last several years, NGS-based analysis has been widely applied to identify CNVs in both healthy and diseased individuals. Correspondingly, the strong demand for NGS-based CNV analyses has fuelled development of numerous computational methods and tools for CNV detection. In this article, we review the recent advances in computational methods pertaining to CNV detection using whole genome and whole exome sequencing data. Additionally, we discuss their strengths and weaknesses and suggest directions for future development.},
author = {Zhao, Min and Wang, Qingguo and Wang, Quan and Jia, Peilin and Zhao, Zhongming},
doi = {10.1186/1471-2105-14-S11-S1},
file = {:home/akira/Downloads/1471-2105-14-S11-S1.pdf:pdf},
issn = {1471-2105},
journal = {BMC Bioinformatics},
mendeley-groups = {TCC},
number = {11},
pages = {S1},
title = {{Computational tools for copy number variation (CNV) detection using next-generation sequencing data: features and perspectives}},
url = {https://doi.org/10.1186/1471-2105-14-S11-S1},
volume = {14},
year = {2013}
}

@article{Redon2006,
abstract = {Copy number variation (CNV) of DNA sequences is functionally significant but has yet to be fully ascertained. We have constructed a first-generation CNV map of the human genome through the study of 270 individuals from four populations with ancestry in Europe, Africa or Asia (the HapMap collection). DNA from these individuals was screened for CNV using two complementary technologies: single-nucleotide polymorphism (SNP) genotyping arrays, and clone-based comparative genomic hybridization. A total of 1,447 copy number variable regions (CNVRs), which can encompass overlapping or adjacent gains or losses, covering 360 megabases (12{\%} of the genome) were identified in these populations. These CNVRs contained hundreds of genes, disease loci, functional elements and segmental duplications. Notably, the CNVRs encompassed more nucleotide content per genome than SNPs, underscoring the importance of CNV in genetic diversity and evolution. The data obtained delineate linkage disequilibrium patterns for many CNVs, and reveal marked variation in copy number among populations. We also demonstrate the utility of this resource for genetic disease studies.},
author = {Redon, Richard and Ishikawa, Shumpei and Fitch, Karen R and Feuk, Lars and Perry, George H and Andrews, T Daniel and Fiegler, Heike and Shapero, Michael H and Carson, Andrew R and Chen, Wenwei and Cho, Eun Kyung and Dallaire, Stephanie and Freeman, Jennifer L and Gonz{\'{a}}lez, Juan R and Gratac{\`{o}}s, M{\`{o}}nica and Huang, Jing and Kalaitzopoulos, Dimitrios and Komura, Daisuke and MacDonald, Jeffrey R and Marshall, Christian R and Mei, Rui and Montgomery, Lyndal and Nishimura, Kunihiro and Okamura, Kohji and Shen, Fan and Somerville, Martin J and Tchinda, Joelle and Valsesia, Armand and Woodwark, Cara and Yang, Fengtang and Zhang, Junjun and Zerjal, Tatiana and Zhang, Jane and Armengol, Lluis and Conrad, Donald F and Estivill, Xavier and Tyler-Smith, Chris and Carter, Nigel P and Aburatani, Hiroyuki and Lee, Charles and Jones, Keith W and Scherer, Stephen W and Hurles, Matthew E},
doi = {10.1038/nature05329},
file = {:home/akira/Downloads/nature05329.pdf:pdf},
issn = {1476-4687},
journal = {Nature},
mendeley-groups = {TCC},
number = {7118},
pages = {444--454},
title = {{Global variation in copy number in the human genome}},
url = {https://doi.org/10.1038/nature05329},
volume = {444},
year = {2006}
}

@article{Sebat2004,
abstract = {The extent to which large duplications and deletions contribute to human genetic variation and diversity is unknown. Here, we show that large-scale copy number polymorphisms (CNPs) (about 100 kilobases and greater) contribute substantially to genomic variation between normal humans. Representational oligonucleotide microarray analysis of 20 individuals revealed a total of 221 copy number differences representing 76 unique CNPs. On average, individuals differed by 11 CNPs, and the average length of a CNP interval was 465 kilobases. We observed copy number variation of 70 different genes within CNP intervals, including genes involved in neurological function, regulation of cell growth, regulation of metabolism, and several genes known to be associated with disease.},
author = {Sebat, Jonathan and Lakshmi, B and Troge, Jennifer and Alexander, Joan and Young, Janet and Lundin, P{\"{a}}r and M{\aa}n{\'{e}}r, Susanne and Massa, Hillary and Walker, Megan and Chi, Maoyen and Navin, Nicholas and Lucito, Robert and Healy, John and Hicks, James and Ye, Kenny and Reiner, Andrew and Gilliam, T Conrad and Trask, Barbara and Patterson, Nick and Zetterberg, Anders and Wigler, Michael},
doi = {10.1126/science.1098918},
file = {:home/akira/Downloads/525.full.pdf:pdf},
journal = {Science},
mendeley-groups = {TCC},
month = {jul},
number = {5683},
pages = {525 LP -- 528},
title = {{Large-Scale Copy Number Polymorphism in the Human Genome}},
url = {http://science.sciencemag.org/content/305/5683/525.abstract},
volume = {305},
year = {2004}
}

@article{Girimurugan2018,
abstract = {Identification of functional elements of a genome often requires dividing a sequence of measurements along a genome into segments where adjacent segments have different properties, such as different mean values. Despite dozens of algorithms developed to address this problem in genomics research, methods with improved accuracy and speed are still needed to effectively tackle both existing and emerging genomic and epigenomic segmentation problems.},
author = {Girimurugan, Senthil B and Liu, Yuhang and Lung, Pei-Yau and Vera, Daniel L and Dennis, Jonathan H and Bass, Hank W and Zhang, Jinfeng},
doi = {10.1186/s12859-018-2140-3},
file = {:home/akira/Downloads/s12859-018-2140-3.pdf:pdf},
issn = {1471-2105},
journal = {BMC Bioinformatics},
mendeley-groups = {TCC},
number = {1},
pages = {131},
title = {{iSeg: an efficient algorithm for segmentation of genomic and epigenomic data}},
url = {https://doi.org/10.1186/s12859-018-2140-3},
volume = {19},
year = {2018}
}

@article{Baldi2001,
abstract = {Motivation: DNA microarrays are now capable of providing genome-wide patterns of gene expression across many different conditions. The first level of analysis of these patterns requires determining whether observed differences in expression are significant or not. Current methods are unsatisfactory due to the lack of a systematic framework that can accommodate noise, variability, and low replication often typical of microarray data.Results: We develop a Bayesian probabilistic framework for microarray data analysis. At the simplest level, we model log-expression values by independent normal distributions, parameterized by corresponding means and variances with hierarchical prior distributions. We derive point estimates for both parameters and hyperparameters, and regularized expressions for the variance of each gene by combining the empirical variance with a local background variance associated with neighboring genes. An additional hyperparameter, inversely related to the number of empirical observations, determines the strength of the background variance. Simulations show that these point estimates, combined with a t -test, provide a systematic inference approach that compares favorably with simple t -test or fold methods, and partly compensate for the lack of replication.Availability: The approach is implemented in software called Cyber-T accessible through a Web interface at www.genomics.uci.edu/software.html. The code is available as Open Source and is written in the freely available statistical language R.Contact: pfbaldi@ics.uci.edu; tdlong@uci.edu*To whom correspondence should be addressed.3Also at Department of Biological Chemistry, College of Medicine, University of California, Irvine.},
author = {Baldi, Pierre and Long, Anthony D},
doi = {10.1093/bioinformatics/17.6.509},
file = {:home/akira/Downloads/170509.pdf:pdf},
issn = {1367-4803},
journal = {Bioinformatics},
mendeley-groups = {TCC},
month = {jun},
number = {6},
pages = {509--519},
title = {{A Bayesian framework for the analysis of microarray expression data: regularized t -test and statistical inferences of gene changes}},
url = {https://doi.org/10.1093/bioinformatics/17.6.509},
volume = {17},
year = {2001}
}

@article{Olshen2004,
abstract = {DNA sequence copy number is the number of copies of DNA at a region of a genome. Cancer progression often involves alterations in DNA copy number. Newly developed microarray technologies enable simultaneous measurement of copy number at thousands of sites in a genome. We have developed a modification of binary segmentation, which we call circular binary segmentation, to translate noisy intensity measurements into regions of equal copy number. The method is evaluated by simulation and is demonstrated on cell line data with known copy number alterations and on a breast cancer cell line data set.},
author = {Olshen, Adam B and Venkatraman, E S and Lucito, Robert and Wigler, Michael},
doi = {10.1093/biostatistics/kxh008},
file = {:home/akira/Downloads/kxh008.pdf:pdf},
issn = {1465-4644},
journal = {Biostatistics},
mendeley-groups = {TCC},
month = {oct},
number = {4},
pages = {557--572},
title = {{Circular binary segmentation for the analysis of array‐based DNA copy number data}},
url = {https://doi.org/10.1093/biostatistics/kxh008},
volume = {5},
year = {2004}
}

@article{Picard2011,
abstract = {The joint segmentation of multiple series is considered. A mixed linear model is used to account for both covariates and correlations between signals. An estimation algorithm based on EM which involves a new dynamic programming strategy for the segmentation step is proposed. The computational efficiency of this procedure is shown and its performance is assessed through simulation experiments. Applications are presented in the field of climatic data analysis. {\textcopyright} 2010 Elsevier B.V. All rights reserved.},
author = {Picard, F. and Lebarbier, E. and Budinsk, E. and Robin, S.},
doi = {10.1016/j.csda.2010.09.015},
file = {:home/akira/Downloads/1-s2.0-S0167947310003580-main.pdf:pdf},
issn = {01679473},
journal = {Computational Statistics and Data Analysis},
keywords = {Dynamic programming,EM algorithm,Mixed linear model,Multivariate Gaussian process,Segmentation},
mendeley-groups = {TCC},
number = {2},
pages = {1160--1170},
publisher = {Elsevier B.V.},
title = {{Joint segmentation of multivariate Gaussian processes using mixed linear models}},
url = {http://dx.doi.org/10.1016/j.csda.2010.09.015},
volume = {55},
year = {2011}
}

@article{Plagnol2012,
abstract = {Motivation: Exome sequencing has proven to be an effective tool to discover the genetic basis of Mendelian disorders. It is well established that copy number variants (CNVs) contribute to the etiology of these disorders. However, calling CNVs from exome sequence data is challenging. A typical read depth strategy consists of using another sample (or a combination of samples) as a reference to control for the variability at the capture and sequencing steps. However, technical variability between samples complicates the analysis and can create spurious CNV calls.Results: Here, we introduce ExomeDepth, a new CNV calling algorithm designed to control for this technical variability. ExomeDepth uses a robust model for the read count data and uses this model to build an optimized reference set in order to maximize the power to detect CNVs. As a result, ExomeDepth is effective across a wider range of exome datasets than the previously existing tools, even for small (e.g. one to two exons) and heterozygous deletions. We used this new approach to analyse exome data from 24 patients with primary immunodeficiencies. Depending on data quality and the exact target region, we find between 170 and 250 exonic CNV calls per sample. Our analysis identified two novel causative deletions in the genes GATA2 and DOCK8.Availability: The code used in this analysis has been implemented into an R package called ExomeDepth and is available at the Comprehensive R Archive Network (CRAN).Contact: v.plagnol@ucl.ac.ukSupplementary Information:Supplementary data are available at Bioinformatics online.},
author = {Plagnol, Vincent and Curtis, James and Epstein, Michael and Mok, Kin Y and Stebbings, Emma and Grigoriadou, Sofia and Wood, Nicholas W and Hambleton, Sophie and Burns, Siobhan O and Thrasher, Adrian J and Kumararatne, Dinakantha and Doffinger, Rainer and Nejentsev, Sergey},
doi = {10.1093/bioinformatics/bts526},
file = {:home/akira/Downloads/bts526.pdf:pdf},
issn = {1367-4803},
journal = {Bioinformatics},
mendeley-groups = {TCC},
month = {aug},
number = {21},
pages = {2747--2754},
title = {{A robust model for read count data in exome sequencing experiments and implications for copy number variant calling}},
url = {https://doi.org/10.1093/bioinformatics/bts526},
volume = {28},
year = {2012}
}

@article{Zou2006,
abstract = {The lasso is a popular technique for simultaneous estimation and variable selection. Lasso variable selection has been shown to be consistent under certain conditions. In this work we derive a necessary condition for the lasso variable selection to be consistent. Consequently, there exist certain scenarios where the lasso is inconsistent for variable selection. We then propose a new version of the lasso, called the adaptive lasso, where adaptive weights are used for penalizing different coefficients in the ?1 penalty. We show that the adaptive lasso enjoys the oracle properties; namely, it performs as well as if the true underlying model were given in advance. Similar to the lasso, the adaptive lasso is shown to be near-minimax optimal. Furthermore, the adaptive lasso can be solved by the same efficient algorithm for solving the lasso. We also discuss the extension of the adaptive lasso in generalized linear models and show that the oracle properties still hold under mild regularity conditions. As a byproduct of our theory, the nonnegative garotte is shown to be consistent for variable selection.},
annote = {doi: 10.1198/016214506000000735},
author = {Zou, Hui},
doi = {10.1198/016214506000000735},
issn = {0162-1459},
journal = {Journal of the American Statistical Association},
mendeley-groups = {TCC},
month = {dec},
number = {476},
pages = {1418--1429},
publisher = {Taylor {\&} Francis},
title = {{The Adaptive Lasso and Its Oracle Properties}},
url = {https://doi.org/10.1198/016214506000000735},
volume = {101},
year = {2006}
}

@article{Jin2016,
abstract = {Abstract A two-stage procedure for simultaneously detecting multiple change-points in linear models is developed. In the cutting stage, the change-point problem is converted into a model selection problem so that a modern model selection method can be applied. In the refining stage, the change-points obtained in the cutting stage are finalized via a refining method. Under mild conditions, consistency of the number of change-point estimates is established. The new procedure is fast and accurate, as shown in simulation studies. Its applicability in real situations is demonstrated via well-log and ozone data. The Canadian Journal of Statistics 44: 161?179; 2016 ? 2016 Statistical Society of Canada},
annote = {doi: 10.1002/cjs.11282},
author = {Jin, Baisuo and Wu, Yuehua and Shi, Xiaoping},
doi = {10.1002/cjs.11282},
file = {:home/akira/Downloads/Jin{\_}et{\_}al-2016-Canadian{\_}Journal{\_}of{\_}Statistics.pdf:pdf},
issn = {0319-5724},
journal = {Canadian Journal of Statistics},
keywords = {Adaptive lasso,Consistency,MCP/SCAD,MSC 2010: Primary 62F99,model selection,multiple change-point detection,secondary 62P25},
mendeley-groups = {TCC},
month = {jun},
number = {2},
pages = {161--179},
publisher = {John Wiley {\&} Sons, Ltd},
title = {{Consistent two-stage multiple change-point detection in linear models}},
url = {https://doi.org/10.1002/cjs.11282},
volume = {44},
year = {2016}
}

@article{Snijders2001,
abstract = {We have assembled arrays of approximately 2,400 BAC clones for measurement of DNA copy number across the human genome. The arrays provide precise measurement (s.d. of log2 ratios=0.05–0.10) in cell lines and clinical material, so that we can reliably detect and quantify high-level amplifications and single-copy alterations in diploid, polyploid and heterogeneous backgrounds.},
author = {Snijders, Antoine M and Nowak, Norma and Segraves, Richard and Blackwood, Stephanie and Brown, Nils and Conroy, Jeffrey and Hamilton, Greg and Hindle, Anna Katherine and Huey, Bing and Kimura, Karen and Law, Sindy and Myambo, Ken and Palmer, Joel and Ylstra, Bauke and Yue, Jingzhu Pearl and Gray, Joe W and Jain, Ajay N and Pinkel, Daniel and Albertson, Donna G},
doi = {10.1038/ng754},
file = {:home/akira/Downloads/ng754.pdf:pdf},
issn = {1546-1718},
journal = {Nature Genetics},
mendeley-groups = {TCC},
number = {3},
pages = {263--264},
title = {{Assembly of microarrays for genome-wide measurement of DNA copy number}},
url = {https://doi.org/10.1038/ng754},
volume = {29},
year = {2001}
}

@article{Chen2015,
abstract = {[We consider the testing and estimation of change-points{\&}{\#}x2014;locations where the distribution abruptly changes{\&}{\#}x2014;in a data sequence. A new approach, based on scan statistics utilizing graphs representing the similarity between observations, is proposed. The graph-based approach is nonparametric, and can be applied to any data set as long as an informative similarity measure on the sample space can be defined. Accurate analytic approximations to the significance of graph-based scan statistics for both the single change-point and the changed interval alternatives are provided. Simulations reveal that the new approach has better power than existing approaches when the dimension of the data is moderate to high. The new approach is illustrated on two applications: The determination of authorship of a classic novel, and the detection of change in a network over time.]},
author = {Chen, Hao and Zhang, Nancy},
file = {:home/akira/Downloads/43556511.pdf:pdf},
issn = {00905364},
journal = {The Annals of Statistics},
mendeley-groups = {TCC},
number = {1},
pages = {139--176},
publisher = {Institute of Mathematical Statistics},
title = {{GRAPH-BASED CHANGE-POINT DETECTION}},
url = {http://www-jstor-org.ez48.periodicos.capes.gov.br/stable/43556511},
volume = {43},
year = {2015}
}
